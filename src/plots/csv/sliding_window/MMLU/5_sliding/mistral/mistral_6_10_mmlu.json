{
    "mmlu": {
        "acc,none": 0.26093149124056403,
        "acc_stderr,none": 0.00367533803499193,
        "alias": "mmlu"
    },
    "mmlu_humanities": {
        "acc,none": 0.24357066950053136,
        "acc_stderr,none": 0.006254099455244496,
        "alias": " - humanities"
    },
    "mmlu_formal_logic": {
        "alias": "  - formal_logic",
        "acc,none": 0.15079365079365079,
        "acc_stderr,none": 0.03200686497287394
    },
    "mmlu_high_school_european_history": {
        "alias": "  - high_school_european_history",
        "acc,none": 0.21818181818181817,
        "acc_stderr,none": 0.03225078108306289
    },
    "mmlu_high_school_us_history": {
        "alias": "  - high_school_us_history",
        "acc,none": 0.2647058823529412,
        "acc_stderr,none": 0.03096451792692339
    },
    "mmlu_high_school_world_history": {
        "alias": "  - high_school_world_history",
        "acc,none": 0.2320675105485232,
        "acc_stderr,none": 0.02747974455080851
    },
    "mmlu_international_law": {
        "alias": "  - international_law",
        "acc,none": 0.34710743801652894,
        "acc_stderr,none": 0.04345724570292534
    },
    "mmlu_jurisprudence": {
        "alias": "  - jurisprudence",
        "acc,none": 0.21296296296296297,
        "acc_stderr,none": 0.03957835471980981
    },
    "mmlu_logical_fallacies": {
        "alias": "  - logical_fallacies",
        "acc,none": 0.2392638036809816,
        "acc_stderr,none": 0.033519538795212696
    },
    "mmlu_moral_disputes": {
        "alias": "  - moral_disputes",
        "acc,none": 0.2254335260115607,
        "acc_stderr,none": 0.02249723019096755
    },
    "mmlu_moral_scenarios": {
        "alias": "  - moral_scenarios",
        "acc,none": 0.24692737430167597,
        "acc_stderr,none": 0.014422292204808838
    },
    "mmlu_philosophy": {
        "alias": "  - philosophy",
        "acc,none": 0.2604501607717042,
        "acc_stderr,none": 0.02492672322484555
    },
    "mmlu_prehistory": {
        "alias": "  - prehistory",
        "acc,none": 0.2222222222222222,
        "acc_stderr,none": 0.02313237623454336
    },
    "mmlu_professional_law": {
        "alias": "  - professional_law",
        "acc,none": 0.2457627118644068,
        "acc_stderr,none": 0.01099615663514269
    },
    "mmlu_world_religions": {
        "alias": "  - world_religions",
        "acc,none": 0.28654970760233917,
        "acc_stderr,none": 0.034678266857038266
    },
    "mmlu_other": {
        "acc,none": 0.24203411651110396,
        "acc_stderr,none": 0.007566394920139754,
        "alias": " - other"
    },
    "mmlu_business_ethics": {
        "alias": "  - business_ethics",
        "acc,none": 0.23,
        "acc_stderr,none": 0.04229525846816505
    },
    "mmlu_clinical_knowledge": {
        "alias": "  - clinical_knowledge",
        "acc,none": 0.2981132075471698,
        "acc_stderr,none": 0.028152837942493875
    },
    "mmlu_college_medicine": {
        "alias": "  - college_medicine",
        "acc,none": 0.2832369942196532,
        "acc_stderr,none": 0.034355680560478746
    },
    "mmlu_global_facts": {
        "alias": "  - global_facts",
        "acc,none": 0.18,
        "acc_stderr,none": 0.038612291966536955
    },
    "mmlu_human_aging": {
        "alias": "  - human_aging",
        "acc,none": 0.1210762331838565,
        "acc_stderr,none": 0.021894174113185772
    },
    "mmlu_management": {
        "alias": "  - management",
        "acc,none": 0.34951456310679613,
        "acc_stderr,none": 0.047211885060971716
    },
    "mmlu_marketing": {
        "alias": "  - marketing",
        "acc,none": 0.2094017094017094,
        "acc_stderr,none": 0.026655699653922744
    },
    "mmlu_medical_genetics": {
        "alias": "  - medical_genetics",
        "acc,none": 0.24,
        "acc_stderr,none": 0.04292346959909284
    },
    "mmlu_miscellaneous": {
        "alias": "  - miscellaneous",
        "acc,none": 0.19923371647509577,
        "acc_stderr,none": 0.014283378044296413
    },
    "mmlu_nutrition": {
        "alias": "  - nutrition",
        "acc,none": 0.23202614379084968,
        "acc_stderr,none": 0.024170840879341016
    },
    "mmlu_professional_accounting": {
        "alias": "  - professional_accounting",
        "acc,none": 0.23049645390070922,
        "acc_stderr,none": 0.025123739226872405
    },
    "mmlu_professional_medicine": {
        "alias": "  - professional_medicine",
        "acc,none": 0.4485294117647059,
        "acc_stderr,none": 0.030211479609121593
    },
    "mmlu_virology": {
        "alias": "  - virology",
        "acc,none": 0.19879518072289157,
        "acc_stderr,none": 0.031069390260789413
    },
    "mmlu_social_sciences": {
        "acc,none": 0.2918427039324017,
        "acc_stderr,none": 0.008150124301804465,
        "alias": " - social sciences"
    },
    "mmlu_econometrics": {
        "alias": "  - econometrics",
        "acc,none": 0.23684210526315788,
        "acc_stderr,none": 0.039994238792813344
    },
    "mmlu_high_school_geography": {
        "alias": "  - high_school_geography",
        "acc,none": 0.35353535353535354,
        "acc_stderr,none": 0.03406086723547153
    },
    "mmlu_high_school_government_and_politics": {
        "alias": "  - high_school_government_and_politics",
        "acc,none": 0.3471502590673575,
        "acc_stderr,none": 0.03435696168361355
    },
    "mmlu_high_school_macroeconomics": {
        "alias": "  - high_school_macroeconomics",
        "acc,none": 0.36153846153846153,
        "acc_stderr,none": 0.024359581465396987
    },
    "mmlu_high_school_microeconomics": {
        "alias": "  - high_school_microeconomics",
        "acc,none": 0.2647058823529412,
        "acc_stderr,none": 0.028657491285071973
    },
    "mmlu_high_school_psychology": {
        "alias": "  - high_school_psychology",
        "acc,none": 0.3504587155963303,
        "acc_stderr,none": 0.020456077599824457
    },
    "mmlu_human_sexuality": {
        "alias": "  - human_sexuality",
        "acc,none": 0.2824427480916031,
        "acc_stderr,none": 0.03948406125768361
    },
    "mmlu_professional_psychology": {
        "alias": "  - professional_psychology",
        "acc,none": 0.2369281045751634,
        "acc_stderr,none": 0.017201662169789775
    },
    "mmlu_public_relations": {
        "alias": "  - public_relations",
        "acc,none": 0.22727272727272727,
        "acc_stderr,none": 0.04013964554072775
    },
    "mmlu_security_studies": {
        "alias": "  - security_studies",
        "acc,none": 0.24081632653061225,
        "acc_stderr,none": 0.027372942201788167
    },
    "mmlu_sociology": {
        "alias": "  - sociology",
        "acc,none": 0.25870646766169153,
        "acc_stderr,none": 0.03096590312357303
    },
    "mmlu_us_foreign_policy": {
        "alias": "  - us_foreign_policy",
        "acc,none": 0.21,
        "acc_stderr,none": 0.040936018074033256
    },
    "mmlu_stem": {
        "acc,none": 0.2752933713923248,
        "acc_stderr,none": 0.007872486246290488,
        "alias": " - stem"
    },
    "mmlu_abstract_algebra": {
        "alias": "  - abstract_algebra",
        "acc,none": 0.28,
        "acc_stderr,none": 0.04512608598542128
    },
    "mmlu_anatomy": {
        "alias": "  - anatomy",
        "acc,none": 0.2222222222222222,
        "acc_stderr,none": 0.035914440841969694
    },
    "mmlu_astronomy": {
        "alias": "  - astronomy",
        "acc,none": 0.17763157894736842,
        "acc_stderr,none": 0.031103182383123384
    },
    "mmlu_college_biology": {
        "alias": "  - college_biology",
        "acc,none": 0.2986111111111111,
        "acc_stderr,none": 0.03827052357950756
    },
    "mmlu_college_chemistry": {
        "alias": "  - college_chemistry",
        "acc,none": 0.2,
        "acc_stderr,none": 0.04020151261036845
    },
    "mmlu_college_computer_science": {
        "alias": "  - college_computer_science",
        "acc,none": 0.34,
        "acc_stderr,none": 0.04760952285695236
    },
    "mmlu_college_mathematics": {
        "alias": "  - college_mathematics",
        "acc,none": 0.19,
        "acc_stderr,none": 0.03942772444036624
    },
    "mmlu_college_physics": {
        "alias": "  - college_physics",
        "acc,none": 0.37254901960784315,
        "acc_stderr,none": 0.04810840148082634
    },
    "mmlu_computer_security": {
        "alias": "  - computer_security",
        "acc,none": 0.2,
        "acc_stderr,none": 0.040201512610368445
    },
    "mmlu_conceptual_physics": {
        "alias": "  - conceptual_physics",
        "acc,none": 0.2127659574468085,
        "acc_stderr,none": 0.026754391348039776
    },
    "mmlu_electrical_engineering": {
        "alias": "  - electrical_engineering",
        "acc,none": 0.22758620689655173,
        "acc_stderr,none": 0.03493950380131184
    },
    "mmlu_elementary_mathematics": {
        "alias": "  - elementary_mathematics",
        "acc,none": 0.26455026455026454,
        "acc_stderr,none": 0.022717467897708607
    },
    "mmlu_high_school_biology": {
        "alias": "  - high_school_biology",
        "acc,none": 0.3161290322580645,
        "acc_stderr,none": 0.026450874489042767
    },
    "mmlu_high_school_chemistry": {
        "alias": "  - high_school_chemistry",
        "acc,none": 0.24630541871921183,
        "acc_stderr,none": 0.030315099285617722
    },
    "mmlu_high_school_computer_science": {
        "alias": "  - high_school_computer_science",
        "acc,none": 0.31,
        "acc_stderr,none": 0.04648231987117316
    },
    "mmlu_high_school_mathematics": {
        "alias": "  - high_school_mathematics",
        "acc,none": 0.26666666666666666,
        "acc_stderr,none": 0.026962424325073828
    },
    "mmlu_high_school_physics": {
        "alias": "  - high_school_physics",
        "acc,none": 0.2913907284768212,
        "acc_stderr,none": 0.03710185726119995
    },
    "mmlu_high_school_statistics": {
        "alias": "  - high_school_statistics",
        "acc,none": 0.48148148148148145,
        "acc_stderr,none": 0.034076320938540516
    },
    "mmlu_machine_learning": {
        "alias": "  - machine_learning",
        "acc,none": 0.24107142857142858,
        "acc_stderr,none": 0.04059867246952687
    }
}